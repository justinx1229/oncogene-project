{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "181ca49b-44a1-46cc-b32f-15f653a7e48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Create points 2 standard deviations apart around 0\n",
    "def density_centers(df, num):\n",
    "    std = np.nanstd(df.iloc[:,1:])\n",
    "    return np.linspace(-std*num, std*num, num=num*2, endpoint=False)[1::2]\n",
    "\n",
    "# Extracts a specific gene\n",
    "def extract(df, name):\n",
    "    return df[df.iloc[:, 0] == name].iloc[:, 1:].to_numpy()[0]\n",
    "\n",
    "# Takes 2 arrays of the same length and drops all columns with NaN present\n",
    "def drop_nan(x, y):\n",
    "    combined = np.array(np.concatenate(([x],[y]), axis=0))\n",
    "    combined = combined[:, ~pd.isna(combined).any(axis=0)]\n",
    "    return combined[0], combined[1]\n",
    "\n",
    "# Convert 2 vectors into a heatmap\n",
    "def densitymap(x, y, xDensityCenters, yDensityCenters, xdiscrete=False, ydiscrete=False, sigma=1):\n",
    "    if len(x) != len(y):\n",
    "        return \"inconsistent size of x and y vectors\"\n",
    "\n",
    "    # Initialize variables\n",
    "    sigma_sq_inv = (1/sigma)**2\n",
    "    mat = np.zeros((len(yDensityCenters), len(xDensityCenters)))\n",
    "\n",
    "    # create density map depending on discreteness of x and y \n",
    "    if not xdiscrete and not ydiscrete:\n",
    "        for pt in range(len(x)):\n",
    "            temp = np.zeros((len(yDensityCenters), len(xDensityCenters)))\n",
    "            for i, center_x in enumerate(xDensityCenters):\n",
    "                for j, center_y in enumerate(yDensityCenters):\n",
    "                    dist_sq = (x[pt] - center_x)**2+(y[pt] - center_y)**2\n",
    "                    temp[j, i] = np.exp(-0.5*sigma_sq_inv*dist_sq)\n",
    "                    \n",
    "            temp /= np.sum(temp)\n",
    "            mat += temp\n",
    "            \n",
    "    elif xdiscrete and ydiscrete:\n",
    "        for i, center_x in enumerate(xDensityCenters):\n",
    "            for j, center_y in enumerate(yDensityCenters):\n",
    "                mat[j, i] += np.sum((x[y==center_y]==center_x))\n",
    "                \n",
    "    elif xdiscrete:\n",
    "        for pt in range(len(x)):\n",
    "            temp = np.zeros(len(yDensityCenters))\n",
    "            for i, center_y in enumerate(yDensityCenters):\n",
    "                dist_sq = (y[pt] - center_y)**2\n",
    "                temp[i] = np.exp(-0.5*sigma_sq_inv*dist_sq)\n",
    "                    \n",
    "            temp /= np.sum(temp)\n",
    "            mat[:, xDensityCenters.index(x[pt])] += temp\n",
    "    else:\n",
    "        for pt in range(len(y)):\n",
    "            temp = np.zeros(len(xDensityCenters))\n",
    "            for i, center_x in enumerate(xDensityCenters):\n",
    "                dist_sq = (x[pt] - center_x)**2\n",
    "                temp[i] = np.exp(-0.5*sigma_sq_inv*dist_sq)\n",
    "                    \n",
    "            temp /= np.sum(temp)\n",
    "            mat[yDensityCenters.index(y[pt])] += temp\n",
    "    \n",
    "    # Normalize the kernel\n",
    "    mat /= len(x) \n",
    "    return mat\n",
    "\n",
    "# Main function that creates features based on datasets and pairs\n",
    "def build_density_map(datasets, pairs, continuous, density_points):\n",
    "\n",
    "    out = pd.DataFrame({'pair':[f'{p1}.{p2}' for p1, p2 in pairs]})\n",
    "\n",
    "    for i in range(len(datasets)):\n",
    "        for j in range(len(datasets)):\n",
    "            \n",
    "            # Initialize dataframes and variables\n",
    "            df1 = datasets[i]\n",
    "            df2 = datasets[j]\n",
    "            mask = df1.columns.str.strip().isin(df2.columns.str.strip())\n",
    "            mask[0] = True\n",
    "            df1 = df1.loc[:, mask]\n",
    "            mask = df2.columns.str.strip().isin(df1.columns.str.strip())\n",
    "            mask[0] = True\n",
    "            df2 = df2.loc[:, mask]\n",
    "    \n",
    "            df1_pts = density_points[i]\n",
    "            df2_pts = density_points[j]\n",
    "\n",
    "            df1_cont = continuous[i]\n",
    "            df2_cont = continuous[j]\n",
    "\n",
    "            temp = pd.DataFrame(index=range(len(out)), \n",
    "                                columns=[f'{datasets[i].name}.{datasets[j].name}.{value}' for value in range(len(df1_pts) * len(df2_pts))])\n",
    "\n",
    "            #Calculate bandwidth\n",
    "            if df1_cont:\n",
    "                if df2_cont:\n",
    "                    std = math.sqrt((np.nanstd(df1.iloc[:,1:].to_numpy())**2\n",
    "                                     +np.nanstd(df2.iloc[:,1:].to_numpy())**2)/2)\n",
    "                else:\n",
    "                    std = np.nanstd(df1.iloc[:,1:].to_numpy())\n",
    "            else:\n",
    "                std = np.nanstd(df2.iloc[:,1:].to_numpy())\n",
    "\n",
    "            # Insert density maps onto final matrix\n",
    "            for index in range(len(pairs)):\n",
    "                p1, p2 = pairs[index]\n",
    "                x = extract(df1, p1)\n",
    "                y = extract(df2, p2)\n",
    "                x, y = drop_nan(x, y)\n",
    "                mat = densitymap(x, y, df1_pts, df2_pts, xdiscrete=not df1_cont, ydiscrete=not df2_cont, sigma=std)\n",
    "                temp.iloc[index] = mat.flatten()\n",
    "\n",
    "            # Logarithmic transformation\n",
    "            temp += 1/len(df1.columns)\n",
    "            temp = temp.map(np.log)\n",
    "            \n",
    "            out = pd.concat([out, temp], axis=1)\n",
    "    \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db11cad-133c-4d53-9f46-46217ad342ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"config\", help=\"configuation file input\")\n",
    "parser.add_arguemtn(\"pairs\", help=\"csv file containing the pairs to make features of\")\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "0fc8fe1c-114e-4117-a58b-98d8629c8624",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = gene_exp, copy_num, shRNA, gene_mut, CRISPR\n",
    "cont = True, False, True, False, True\n",
    "points = density_centers(gene_exp, 7), [0,1,2,3,4,6,8], density_centers(shRNA, 7), [0, 1], density_centers(CRISPR, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a6a873d-0696-4125-8e20-1c1c1a1a72fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pos1_feat = build_density_map(datasets, pos1_t, cont, points)\n",
    "pos1_feat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
